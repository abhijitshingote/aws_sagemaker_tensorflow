{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c74a66",
   "metadata": {},
   "source": [
    "## Some issue with the evaluate function, so disregard the calculated recall and precision. However, the crosstab showing actuals and predictions is clear. Model tuning with recall , precision or balanced tuning - is clear in the crosstab table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe1aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c534768_creditcardfraud/creditcardfraud.zip\n",
    "# !unzip creditcardfraud\n",
    "# !rm creditcardfraud.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b29029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import os\n",
    "import sagemaker\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e89f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701687ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>...</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "      <td>284315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>...</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time      V1      V2      V3      V4      V5      V6      V7      V8  \\\n",
       "Class                                                                           \n",
       "0      284315  284315  284315  284315  284315  284315  284315  284315  284315   \n",
       "1         492     492     492     492     492     492     492     492     492   \n",
       "\n",
       "           V9  ...     V20     V21     V22     V23     V24     V25     V26  \\\n",
       "Class          ...                                                           \n",
       "0      284315  ...  284315  284315  284315  284315  284315  284315  284315   \n",
       "1         492  ...     492     492     492     492     492     492     492   \n",
       "\n",
       "          V27     V28  Amount  \n",
       "Class                          \n",
       "0      284315  284315  284315  \n",
       "1         492     492     492  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Class').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83d01e2",
   "metadata": {},
   "source": [
    "# Cleaning steps\n",
    "1. NUll removal\n",
    "2. feature reduction\n",
    "3. scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81a778db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fababcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() # looks like its already scaled except for amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "064b7b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "df['Amount']=scaler.fit_transform(df[['Amount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b3cf7",
   "metadata": {},
   "source": [
    "## Train, Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81adea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "148b1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['Class'],axis=1)\n",
    "y=df[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af967902",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b67722a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='data_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([y_train,X_train],axis=1).to_csv(os.path.join(data_dir,'train.csv'),header=False,index=False)\n",
    "pd.concat([y_test,X_test],axis=1).to_csv(os.path.join(data_dir,'test.csv'),header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "518b5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "session=sagemaker.Session()\n",
    "role=sagemaker.get_execution_role()\n",
    "region=session.boto_region_name\n",
    "bucket=session.default_bucket()\n",
    "prefix='payment_fraud_detection'\n",
    "image_uri=sagemaker.image_uris.retrieve(framework='linear-learner',region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a103057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_data=session.upload_data(os.path.join(data_dir,'train.csv'),bucket=bucket,key_prefix=prefix)\n",
    "s3_test_data=session.upload_data(os.path.join(data_dir,'test.csv'),bucket=bucket,key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_learner=sagemaker.estimator.Estimator(image_uri=image_uri,\n",
    "                                             role=role,\n",
    "                                             instance_count=1,\n",
    "                                             instance_type='ml.m5.large',\n",
    "                                             use_spot_instances=True,\n",
    "                                             max_run=3600,\n",
    "                                             max_wait=3600,\n",
    "                                             sagemaker_session=session,\n",
    "                                             hyperparameters={\n",
    "                                                 'predictor_type':'binary_classifier',\n",
    "                                                 'epochs':5,\n",
    "                                                 'num_models':5,\n",
    "                                                 'loss':'logistic'\n",
    "                                             }\n",
    "                                             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Should test this later\n",
    "# sagemaker.inputs.TransformInput()\n",
    "# s3_input_test=sagemaker.s3_input(s3_data=s3_test_data,\n",
    "#                                   content_type='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cda69b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train=sagemaker.inputs.TrainingInput(s3_data=s3_train_data,\n",
    "                                  content_type='text/csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b46076",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_learner.fit({'train':s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# deploy and create a predictor\n",
    "linear_predictor = linear_learner.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de07f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to evaluate the endpoint on test data\n",
    "# returns a variety of model metrics\n",
    "def evaluate(predictor, test_features, test_labels, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  \n",
    "    Return binary classification metrics.\n",
    "    :param predictor: A prediction endpoint\n",
    "    :param test_features: Test features\n",
    "    :param test_labels: Class labels for test data\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We have a lot of test data, so we'll split it into batches of 100\n",
    "    # split the test data set into batches and evaluate using prediction endpoint    \n",
    "    prediction_batches = [linear_predictor.predict(batch) for batch in np.array_split(test_features, 100)]\n",
    "    \n",
    "    prediction_batches2=[[x for x in batch['predictions']] for batch in prediction_batches]\n",
    "    prediction_batches=None\n",
    "    test_preds = np.array([score['predicted_label'] for batch in prediction_batches2 for score in batch])\n",
    "    prediction_batches2=None\n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    # printing a table of metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels.flatten(), test_preds, rownames=['actual (row)'], colnames=['prediction (col)']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eafdd340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "linear_predictor.serializer = CSVSerializer()\n",
    "linear_predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# y=np.random.randint(-1, high=1, size=(1,29), dtype=int)\n",
    "# print(y.shape)\n",
    "# linear_predictor.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed7ca6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disconnected session so creating predictor object from an already existing endpoint\n",
    "# from sagemaker.predictor import Predictor\n",
    "\n",
    "# linear_predictor = Predictor(endpoint_name='linear-learner-2021-05-02-14-35-19-535', sagemaker_session=session)\n",
    "# linear_predictor.serializer = CSVSerializer()\n",
    "# linear_predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62e3402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for simple, LinearLearner.\n",
      "\n",
      "prediction (col)      0    1\n",
      "actual (row)                \n",
      "0                 93804   34\n",
      "1                    25  124\n",
      "\n",
      "Recall:     0.002\n",
      "Precision:  0.002\n",
      "Accuracy:   0.997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for simple, LinearLearner.\\n')\n",
    "\n",
    "# get metrics for linear predictor\n",
    "metrics = evaluate(linear_predictor, \n",
    "                   np.array(X_test).astype('float32'), \n",
    "                   np.array(y_test), \n",
    "                   verbose=True) # verbose means we'll print out the metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e943a062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'a25dd07b-56b0-4d24-9a11-7e49f317c466',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a25dd07b-56b0-4d24-9a11-7e49f317c466',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Sun, 02 May 2021 16:15:44 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.client('sagemaker').delete_endpoint(EndpointName=linear_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed1e352",
   "metadata": {},
   "source": [
    "# Adjust for class imbalance and a target recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a08d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_learner=sagemaker.estimator.Estimator(image_uri=image_uri,\n",
    "                                             role=role,\n",
    "                                             instance_count=1,\n",
    "                                             instance_type='ml.m5.large',\n",
    "                                             use_spot_instances=True,\n",
    "                                             max_run=3600,\n",
    "                                             max_wait=3600,\n",
    "                                             sagemaker_session=session,\n",
    "                                             hyperparameters={\n",
    "                                                 'predictor_type':'binary_classifier',\n",
    "                                                 'epochs':5,\n",
    "                                                 'num_models':5,\n",
    "                                                 'loss':'logistic',\n",
    "                                                 'binary_classifier_model_selection_criteria':'precision_at_target_recall',\n",
    "                                                 'target_recall':0.9,\n",
    "                                                 'positive_example_weight_mult':'balanced'\n",
    "                                             }\n",
    "                                             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09740787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-02 16:17:20 Starting - Starting the training job...\n",
      "2021-05-02 16:17:47 Starting - Launching requested ML instancesProfilerReport-1619972239: InProgress\n",
      "......\n",
      "2021-05-02 16:18:47 Starting - Preparing the instances for training.........\n",
      "2021-05-02 16:20:07 Downloading - Downloading input data...\n",
      "2021-05-02 16:20:48 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:47 INFO 140135845263168] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:47 INFO 140135845263168] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'loss': 'logistic', 'positive_example_weight_mult': 'balanced', 'num_models': '5', 'predictor_type': 'binary_classifier', 'epochs': '5', 'target_recall': '0.9', 'binary_classifier_model_selection_criteria': 'precision_at_target_recall'}\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:47 INFO 140135845263168] Final configuration: {'mini_batch_size': '1000', 'epochs': '5', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'precision_at_target_recall', 'f_beta': '1.0', 'target_recall': '0.9', 'target_precision': '0.8', 'num_models': '5', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'logistic', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': 'balanced', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:47 WARNING 140135845263168] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:47 INFO 140135845263168] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:47 INFO 140135845263168] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:47 INFO 140135845263168] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:48 INFO 140135845263168] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f739574a450>\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:48 INFO 140135845263168] Scaling model computed with parameters:\n",
      " {'stdev_label': None, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[1.921056   1.585623   1.5384369  1.4117886  1.4754612  1.3548591\n",
      " 1.3619956  1.2269058  1.0913196  1.1119138  1.0236617  1.0091705\n",
      " 0.99190587 0.97665846 0.9158035  0.8923888  0.86465156 0.82957035\n",
      " 0.81450754 0.74808365 0.71654993 0.7233224  0.61551696 0.61239475\n",
      " 0.5230677  0.47883382 0.39578062 0.27835187 1.1085387 ]\u001b[0m\n",
      "\u001b[34m<NDArray 29 @cpu(0)>, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[-0.01492692  0.01548622  0.01687461  0.00883467 -0.01302119  0.00888218\n",
      "  0.01583095  0.00887387  0.00462827 -0.00665041  0.00538395 -0.00234602\n",
      " -0.0106867  -0.01066171 -0.00255939 -0.00174425  0.00505954  0.00477424\n",
      "  0.00501187  0.01058327 -0.00465694  0.00011442  0.00475777 -0.00947659\n",
      "  0.00264684 -0.0026146   0.00532054 -0.00032971  0.00783072]\u001b[0m\n",
      "\u001b[34m<NDArray 29 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:48 INFO 140135845263168] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:48 INFO 140135845263168] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:48 INFO 140135845263168] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972448.269385, \"EndTime\": 1619972448.2694144, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12000.0, \"count\": 1, \"min\": 12000, \"max\": 12000}, \"Total Batches Seen\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Max Records Seen Between Resets\": {\"sum\": 11000.0, \"count\": 1, \"min\": 11000, \"max\": 11000}, \"Max Batches Seen Between Resets\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972451.9817116, \"EndTime\": 1619972451.981822, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.5001367095144171, \"count\": 1, \"min\": 0.5001367095144171, \"max\": 0.5001367095144171}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972451.981919, \"EndTime\": 1619972451.9819338, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.663207278281764, \"count\": 1, \"min\": 0.663207278281764, \"max\": 0.663207278281764}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972451.981979, \"EndTime\": 1619972451.9819906, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.48893841608950966, \"count\": 1, \"min\": 0.48893841608950966, \"max\": 0.48893841608950966}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972451.982027, \"EndTime\": 1619972451.9820378, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.5161008377878289, \"count\": 1, \"min\": 0.5161008377878289, \"max\": 0.5161008377878289}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972451.9820738, \"EndTime\": 1619972451.9820843, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.5276125345330489, \"count\": 1, \"min\": 0.5276125345330489, \"max\": 0.5276125345330489}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:51 INFO 140135845263168] #quality_metric: host=algo-1, epoch=0, train binary_classification_weighted_cross_entropy_objective <loss>=0.5001367095144171\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:51 INFO 140135845263168] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=binary_classification_weighted_cross_entropy_objective, value=0.48893841608950966\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:51 INFO 140135845263168] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:51 INFO 140135845263168] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:51 INFO 140135845263168] Saved checkpoint to \"/tmp/tmpbsc82itn/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:51 INFO 140135845263168] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972448.26976, \"EndTime\": 1619972451.9949212, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 202820.0, \"count\": 1, \"min\": 202820, \"max\": 202820}, \"Total Batches Seen\": {\"sum\": 203.0, \"count\": 1, \"min\": 203, \"max\": 203}, \"Max Records Seen Between Resets\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:51 INFO 140135845263168] #throughput_metric: host=algo-1, train throughput=51223.23399520918 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972456.573063, \"EndTime\": 1619972456.5730994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3535774673060367, \"count\": 1, \"min\": 0.3535774673060367, \"max\": 0.3535774673060367}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972456.57317, \"EndTime\": 1619972456.573203, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.40346363726164164, \"count\": 1, \"min\": 0.40346363726164164, \"max\": 0.40346363726164164}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972456.5732493, \"EndTime\": 1619972456.5732808, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.35002635333412574, \"count\": 1, \"min\": 0.35002635333412574, \"max\": 0.35002635333412574}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972456.5733204, \"EndTime\": 1619972456.5733302, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3534462167840255, \"count\": 1, \"min\": 0.3534462167840255, \"max\": 0.3534462167840255}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972456.5733685, \"EndTime\": 1619972456.5733807, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.4107121356361791, \"count\": 1, \"min\": 0.4107121356361791, \"max\": 0.4107121356361791}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:56 INFO 140135845263168] #quality_metric: host=algo-1, epoch=1, train binary_classification_weighted_cross_entropy_objective <loss>=0.3535774673060367\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:56 INFO 140135845263168] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=binary_classification_weighted_cross_entropy_objective, value=0.35002635333412574\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:56 INFO 140135845263168] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:56 INFO 140135845263168] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:56 INFO 140135845263168] Saved checkpoint to \"/tmp/tmp2x5hlore/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:56 INFO 140135845263168] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972451.9951665, \"EndTime\": 1619972456.5811853, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 393640.0, \"count\": 1, \"min\": 393640, \"max\": 393640}, \"Total Batches Seen\": {\"sum\": 394.0, \"count\": 1, \"min\": 394, \"max\": 394}, \"Max Records Seen Between Resets\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:20:56 INFO 140135845263168] #throughput_metric: host=algo-1, train throughput=41607.86360498026 records/second\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"StartTime\": 1619972460.2543287, \"EndTime\": 1619972460.2543836, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3260033696626362, \"count\": 1, \"min\": 0.3260033696626362, \"max\": 0.3260033696626362}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972460.254487, \"EndTime\": 1619972460.2545362, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3515915467513235, \"count\": 1, \"min\": 0.3515915467513235, \"max\": 0.3515915467513235}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972460.254618, \"EndTime\": 1619972460.2546315, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3242604337993421, \"count\": 1, \"min\": 0.3242604337993421, \"max\": 0.3242604337993421}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972460.2547607, \"EndTime\": 1619972460.2547755, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3231616814462762, \"count\": 1, \"min\": 0.3231616814462762, \"max\": 0.3231616814462762}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972460.2548454, \"EndTime\": 1619972460.2549186, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3899737661863628, \"count\": 1, \"min\": 0.3899737661863628, \"max\": 0.3899737661863628}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:00 INFO 140135845263168] #quality_metric: host=algo-1, epoch=2, train binary_classification_weighted_cross_entropy_objective <loss>=0.3260033696626362\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:00 INFO 140135845263168] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=binary_classification_weighted_cross_entropy_objective, value=0.3231616814462762\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:00 INFO 140135845263168] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:00 INFO 140135845263168] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:00 INFO 140135845263168] Saved checkpoint to \"/tmp/tmphzcg4lcz/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:00 INFO 140135845263168] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972456.5814526, \"EndTime\": 1619972460.2667024, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 584460.0, \"count\": 1, \"min\": 584460, \"max\": 584460}, \"Total Batches Seen\": {\"sum\": 585.0, \"count\": 1, \"min\": 585, \"max\": 585}, \"Max Records Seen Between Resets\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:00 INFO 140135845263168] #throughput_metric: host=algo-1, train throughput=51774.33906260522 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972464.2247345, \"EndTime\": 1619972464.2247705, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.31368626456009713, \"count\": 1, \"min\": 0.31368626456009713, \"max\": 0.31368626456009713}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972464.2248476, \"EndTime\": 1619972464.224862, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.32853144161826686, \"count\": 1, \"min\": 0.32853144161826686, \"max\": 0.32853144161826686}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972464.224907, \"EndTime\": 1619972464.2249382, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3122434365925036, \"count\": 1, \"min\": 0.3122434365925036, \"max\": 0.3122434365925036}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972464.224983, \"EndTime\": 1619972464.2249932, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.31018476132844625, \"count\": 1, \"min\": 0.31018476132844625, \"max\": 0.31018476132844625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972464.2250578, \"EndTime\": 1619972464.2250695, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.38734894063849196, \"count\": 1, \"min\": 0.38734894063849196, \"max\": 0.38734894063849196}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:04 INFO 140135845263168] #quality_metric: host=algo-1, epoch=3, train binary_classification_weighted_cross_entropy_objective <loss>=0.31368626456009713\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:04 INFO 140135845263168] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=binary_classification_weighted_cross_entropy_objective, value=0.31018476132844625\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:04 INFO 140135845263168] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:04 INFO 140135845263168] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:04 INFO 140135845263168] Saved checkpoint to \"/tmp/tmpdv07jmvj/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:04 INFO 140135845263168] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972460.2673788, \"EndTime\": 1619972464.232811, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 775280.0, \"count\": 1, \"min\": 775280, \"max\": 775280}, \"Total Batches Seen\": {\"sum\": 776.0, \"count\": 1, \"min\": 776, \"max\": 776}, \"Max Records Seen Between Resets\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:04 INFO 140135845263168] #throughput_metric: host=algo-1, train throughput=48119.14571792396 records/second\u001b[0m\n",
      "\n",
      "2021-05-02 16:21:16 Uploading - Uploading generated training model\u001b[34m#metrics {\"StartTime\": 1619972469.5451317, \"EndTime\": 1619972469.5452106, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3065602360374049, \"count\": 1, \"min\": 0.3065602360374049, \"max\": 0.3065602360374049}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972469.5454426, \"EndTime\": 1619972469.5454695, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3160341179697137, \"count\": 1, \"min\": 0.3160341179697137, \"max\": 0.3160341179697137}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972469.5455987, \"EndTime\": 1619972469.5456157, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3051895757574784, \"count\": 1, \"min\": 0.3051895757574784, \"max\": 0.3051895757574784}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972469.5457158, \"EndTime\": 1619972469.545749, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.30306260086862663, \"count\": 1, \"min\": 0.30306260086862663, \"max\": 0.30306260086862663}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972469.5458517, \"EndTime\": 1619972469.5458667, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.36318701348555715, \"count\": 1, \"min\": 0.36318701348555715, \"max\": 0.36318701348555715}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:09 INFO 140135845263168] #quality_metric: host=algo-1, epoch=4, train binary_classification_weighted_cross_entropy_objective <loss>=0.3065602360374049\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:09 INFO 140135845263168] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=binary_classification_weighted_cross_entropy_objective, value=0.30306260086862663\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:09 INFO 140135845263168] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:09 INFO 140135845263168] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:09 INFO 140135845263168] Saved checkpoint to \"/tmp/tmpn4rkj58j/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:09 INFO 140135845263168] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972464.2330782, \"EndTime\": 1619972469.556726, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 966100.0, \"count\": 1, \"min\": 966100, \"max\": 966100}, \"Total Batches Seen\": {\"sum\": 967.0, \"count\": 1, \"min\": 967, \"max\": 967}, \"Max Records Seen Between Resets\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:09 INFO 140135845263168] #throughput_metric: host=algo-1, train throughput=35842.88587065219 records/second\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:09 WARNING 140135845263168] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:09 WARNING 140135845263168] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] #train_score (algo-1) : ('binary_classification_weighted_cross_entropy_objective', 0.29129383753660704)\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] #train_score (algo-1) : ('binary_classification_accuracy', 0.9834398909967509)\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] #train_score (algo-1) : ('binary_f_1.000', 0.16357861302276336)\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] #train_score (algo-1) : ('precision', 0.08995633187772925)\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] #train_score (algo-1) : ('recall', 0.9008746355685131)\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] #train_score (algo-1) : ('roc_auc_score', 0.9846922665884793)\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] #quality_metric: host=algo-1, train binary_classification_weighted_cross_entropy_objective <loss>=0.29129383753660704\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.9834398909967509\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.16357861302276336\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] #quality_metric: host=algo-1, train precision <score>=0.08995633187772925\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] #quality_metric: host=algo-1, train recall <score>=0.9008746355685131\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] #quality_metric: host=algo-1, train roc_auc_score <score>=0.9846922665884793\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.005, \"wd\": 0.0001, \"l1\": 0.0, \"lr_scheduler_step\": 100, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 0.0001}\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] Saved checkpoint to \"/tmp/tmpq40v9y20/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:21:15 INFO 140135845263168] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619972447.953403, \"EndTime\": 1619972475.9256582, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 299.09753799438477, \"count\": 1, \"min\": 299.09753799438477, \"max\": 299.09753799438477}, \"epochs\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"check_early_stopping.time\": {\"sum\": 5.936145782470703, \"count\": 5, \"min\": 0.8237361907958984, \"max\": 1.8908977508544922}, \"update.time\": {\"sum\": 21266.420602798462, \"count\": 5, \"min\": 3680.978298187256, \"max\": 5320.691108703613}, \"finalize.time\": {\"sum\": 6364.402770996094, \"count\": 1, \"min\": 6364.402770996094, \"max\": 6364.402770996094}, \"setuptime\": {\"sum\": 24.690866470336914, \"count\": 1, \"min\": 24.690866470336914, \"max\": 24.690866470336914}, \"totaltime\": {\"sum\": 28202.362537384033, \"count\": 1, \"min\": 28202.362537384033, \"max\": 28202.362537384033}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-05-02 16:21:48 Completed - Training job completed\n",
      "Training seconds: 89\n",
      "Billable seconds: 41\n",
      "Managed Spot Training savings: 53.9%\n"
     ]
    }
   ],
   "source": [
    "linear_learner.fit({'train':s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b44db8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "# deploy and create a predictor\n",
    "linear_predictor = linear_learner.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae4d3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictor.serializer = CSVSerializer()\n",
    "linear_predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "198bcfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for simple, LinearLearner.\n",
      "\n",
      "prediction (col)      0     1\n",
      "actual (row)                 \n",
      "0                 92314  1524\n",
      "1                    15   134\n",
      "\n",
      "Recall:     0.018\n",
      "Precision:  0.002\n",
      "Accuracy:   0.981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for simple, LinearLearner.\\n')\n",
    "\n",
    "# get metrics for linear predictor\n",
    "metrics = evaluate(linear_predictor, \n",
    "                   np.array(X_test).astype('float32'), \n",
    "                   np.array(y_test), \n",
    "                   verbose=True) # verbose means we'll print out the metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "428f6430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'aec550aa-d6c3-4907-8c06-90cfc7654ca4',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'aec550aa-d6c3-4907-8c06-90cfc7654ca4',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Sun, 02 May 2021 16:32:39 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.client('sagemaker').delete_endpoint(EndpointName=linear_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed8e20",
   "metadata": {},
   "source": [
    "# Adjust for class imbalance and a target precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df8b3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_learner=sagemaker.estimator.Estimator(image_uri=image_uri,\n",
    "                                             role=role,\n",
    "                                             instance_count=1,\n",
    "                                             instance_type='ml.m5.large',\n",
    "                                             use_spot_instances=True,\n",
    "                                             max_run=3600,\n",
    "                                             max_wait=3600,\n",
    "                                             sagemaker_session=session,\n",
    "                                             hyperparameters={\n",
    "                                                 'predictor_type':'binary_classifier',\n",
    "                                                 'epochs':5,\n",
    "                                                 'num_models':5,\n",
    "                                                 'loss':'logistic',\n",
    "                                                 'binary_classifier_model_selection_criteria':'recall_at_target_precision',\n",
    "                                                 'target_precision':0.9,\n",
    "                                                 'positive_example_weight_mult':'balanced'\n",
    "                                             }\n",
    "                                             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "716472e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-02 16:32:40 Starting - Starting the training job...\n",
      "2021-05-02 16:33:03 Starting - Launching requested ML instancesProfilerReport-1619973159: InProgress\n",
      ".........\n",
      "2021-05-02 16:34:23 Starting - Preparing the instances for training......\n",
      "2021-05-02 16:35:25 Downloading - Downloading input data...\n",
      "2021-05-02 16:36:04 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:23 INFO 140358224295744] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:23 INFO 140358224295744] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'loss': 'logistic', 'positive_example_weight_mult': 'balanced', 'num_models': '5', 'predictor_type': 'binary_classifier', 'target_precision': '0.9', 'epochs': '5', 'binary_classifier_model_selection_criteria': 'recall_at_target_precision'}\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:23 INFO 140358224295744] Final configuration: {'mini_batch_size': '1000', 'epochs': '5', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'recall_at_target_precision', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.9', 'num_models': '5', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'logistic', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': 'balanced', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:23 WARNING 140358224295744] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:24 INFO 140358224295744] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:24 INFO 140358224295744] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:24 INFO 140358224295744] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:24 INFO 140358224295744] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7fa74fee8c90>\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:24 INFO 140358224295744] Scaling model computed with parameters:\n",
      " {'stdev_label': None, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[1.921056   1.585623   1.5384369  1.4117886  1.4754612  1.3548591\n",
      " 1.3619956  1.2269058  1.0913196  1.1119138  1.0236617  1.0091705\n",
      " 0.99190587 0.97665846 0.9158035  0.8923888  0.86465156 0.82957035\n",
      " 0.81450754 0.74808365 0.71654993 0.7233224  0.61551696 0.61239475\n",
      " 0.5230677  0.47883382 0.39578062 0.27835187 1.1085387 ]\u001b[0m\n",
      "\u001b[34m<NDArray 29 @cpu(0)>, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[-0.01492692  0.01548622  0.01687461  0.00883467 -0.01302119  0.00888218\n",
      "  0.01583095  0.00887387  0.00462827 -0.00665041  0.00538395 -0.00234602\n",
      " -0.0106867  -0.01066171 -0.00255939 -0.00174425  0.00505954  0.00477424\n",
      "  0.00501187  0.01058327 -0.00465694  0.00011442  0.00475777 -0.00947659\n",
      "  0.00264684 -0.0026146   0.00532054 -0.00032971  0.00783072]\u001b[0m\n",
      "\u001b[34m<NDArray 29 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:24 INFO 140358224295744] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:24 INFO 140358224295744] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:24 INFO 140358224295744] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973384.5131032, \"EndTime\": 1619973384.5131361, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12000.0, \"count\": 1, \"min\": 12000, \"max\": 12000}, \"Total Batches Seen\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Max Records Seen Between Resets\": {\"sum\": 11000.0, \"count\": 1, \"min\": 11000, \"max\": 11000}, \"Max Batches Seen Between Resets\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-05-02 16:36:24 Training - Training image download completed. Training in progress.\u001b[34m#metrics {\"StartTime\": 1619973387.849576, \"EndTime\": 1619973387.8496134, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.5001367095144171, \"count\": 1, \"min\": 0.5001367095144171, \"max\": 0.5001367095144171}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973387.8496778, \"EndTime\": 1619973387.8497071, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.663207278281764, \"count\": 1, \"min\": 0.663207278281764, \"max\": 0.663207278281764}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973387.8497503, \"EndTime\": 1619973387.8497872, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.48893841608950966, \"count\": 1, \"min\": 0.48893841608950966, \"max\": 0.48893841608950966}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973387.8498263, \"EndTime\": 1619973387.8498356, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.5161008377878289, \"count\": 1, \"min\": 0.5161008377878289, \"max\": 0.5161008377878289}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973387.849939, \"EndTime\": 1619973387.8499517, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.5276125345330489, \"count\": 1, \"min\": 0.5276125345330489, \"max\": 0.5276125345330489}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:27 INFO 140358224295744] #quality_metric: host=algo-1, epoch=0, train binary_classification_weighted_cross_entropy_objective <loss>=0.5001367095144171\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:27 INFO 140358224295744] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=binary_classification_weighted_cross_entropy_objective, value=0.48893841608950966\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:27 INFO 140358224295744] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:27 INFO 140358224295744] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:27 INFO 140358224295744] Saved checkpoint to \"/tmp/tmpaqc00roj/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:27 INFO 140358224295744] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973384.5134459, \"EndTime\": 1619973387.861855, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 202820.0, \"count\": 1, \"min\": 202820, \"max\": 202820}, \"Total Batches Seen\": {\"sum\": 203.0, \"count\": 1, \"min\": 203, \"max\": 203}, \"Max Records Seen Between Resets\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:27 INFO 140358224295744] #throughput_metric: host=algo-1, train throughput=56985.68369968273 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973392.0010338, \"EndTime\": 1619973392.001065, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3535774673060367, \"count\": 1, \"min\": 0.3535774673060367, \"max\": 0.3535774673060367}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973392.0011277, \"EndTime\": 1619973392.0011592, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.40346363726164164, \"count\": 1, \"min\": 0.40346363726164164, \"max\": 0.40346363726164164}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973392.0012012, \"EndTime\": 1619973392.0012453, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.35002635333412574, \"count\": 1, \"min\": 0.35002635333412574, \"max\": 0.35002635333412574}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973392.001287, \"EndTime\": 1619973392.001298, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3534462167840255, \"count\": 1, \"min\": 0.3534462167840255, \"max\": 0.3534462167840255}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973392.001331, \"EndTime\": 1619973392.0013394, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.4107121356361791, \"count\": 1, \"min\": 0.4107121356361791, \"max\": 0.4107121356361791}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:32 INFO 140358224295744] #quality_metric: host=algo-1, epoch=1, train binary_classification_weighted_cross_entropy_objective <loss>=0.3535774673060367\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:32 INFO 140358224295744] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=binary_classification_weighted_cross_entropy_objective, value=0.35002635333412574\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:32 INFO 140358224295744] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:32 INFO 140358224295744] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:32 INFO 140358224295744] Saved checkpoint to \"/tmp/tmplg363hub/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:32 INFO 140358224295744] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973387.8622518, \"EndTime\": 1619973392.0085423, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 393640.0, \"count\": 1, \"min\": 393640, \"max\": 393640}, \"Total Batches Seen\": {\"sum\": 394.0, \"count\": 1, \"min\": 394, \"max\": 394}, \"Max Records Seen Between Resets\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:32 INFO 140358224295744] #throughput_metric: host=algo-1, train throughput=46020.176322384825 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973395.2280734, \"EndTime\": 1619973395.2281046, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3260033696626362, \"count\": 1, \"min\": 0.3260033696626362, \"max\": 0.3260033696626362}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973395.2281682, \"EndTime\": 1619973395.2281816, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3515915467513235, \"count\": 1, \"min\": 0.3515915467513235, \"max\": 0.3515915467513235}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973395.2283847, \"EndTime\": 1619973395.228401, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3242604337993421, \"count\": 1, \"min\": 0.3242604337993421, \"max\": 0.3242604337993421}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973395.2284393, \"EndTime\": 1619973395.2284496, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3231616814462762, \"count\": 1, \"min\": 0.3231616814462762, \"max\": 0.3231616814462762}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973395.2284946, \"EndTime\": 1619973395.228505, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3899737661863628, \"count\": 1, \"min\": 0.3899737661863628, \"max\": 0.3899737661863628}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:35 INFO 140358224295744] #quality_metric: host=algo-1, epoch=2, train binary_classification_weighted_cross_entropy_objective <loss>=0.3260033696626362\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:35 INFO 140358224295744] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=binary_classification_weighted_cross_entropy_objective, value=0.3231616814462762\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:35 INFO 140358224295744] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:35 INFO 140358224295744] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:35 INFO 140358224295744] Saved checkpoint to \"/tmp/tmp60iywrbs/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:35 INFO 140358224295744] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973392.0089, \"EndTime\": 1619973395.2355218, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 584460.0, \"count\": 1, \"min\": 584460, \"max\": 584460}, \"Total Batches Seen\": {\"sum\": 585.0, \"count\": 1, \"min\": 585, \"max\": 585}, \"Max Records Seen Between Resets\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:35 INFO 140358224295744] #throughput_metric: host=algo-1, train throughput=59135.85567831444 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973398.4964023, \"EndTime\": 1619973398.4964366, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.31368626456009713, \"count\": 1, \"min\": 0.31368626456009713, \"max\": 0.31368626456009713}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973398.496502, \"EndTime\": 1619973398.4965148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.32853144161826686, \"count\": 1, \"min\": 0.32853144161826686, \"max\": 0.32853144161826686}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973398.4965522, \"EndTime\": 1619973398.4965618, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3122434365925036, \"count\": 1, \"min\": 0.3122434365925036, \"max\": 0.3122434365925036}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973398.496592, \"EndTime\": 1619973398.4966002, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.31018476132844625, \"count\": 1, \"min\": 0.31018476132844625, \"max\": 0.31018476132844625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973398.4966295, \"EndTime\": 1619973398.496637, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.38734894063849196, \"count\": 1, \"min\": 0.38734894063849196, \"max\": 0.38734894063849196}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:38 INFO 140358224295744] #quality_metric: host=algo-1, epoch=3, train binary_classification_weighted_cross_entropy_objective <loss>=0.31368626456009713\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:38 INFO 140358224295744] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=binary_classification_weighted_cross_entropy_objective, value=0.31018476132844625\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:38 INFO 140358224295744] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:38 INFO 140358224295744] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:38 INFO 140358224295744] Saved checkpoint to \"/tmp/tmp0b9t817c/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:38 INFO 140358224295744] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973395.2357593, \"EndTime\": 1619973398.5059452, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 775280.0, \"count\": 1, \"min\": 775280, \"max\": 775280}, \"Total Batches Seen\": {\"sum\": 776.0, \"count\": 1, \"min\": 776, \"max\": 776}, \"Max Records Seen Between Resets\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:38 INFO 140358224295744] #throughput_metric: host=algo-1, train throughput=58349.19705990015 records/second\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"StartTime\": 1619973401.8050601, \"EndTime\": 1619973401.805091, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3065602360374049, \"count\": 1, \"min\": 0.3065602360374049, \"max\": 0.3065602360374049}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973401.8051527, \"EndTime\": 1619973401.8051655, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3160341179697137, \"count\": 1, \"min\": 0.3160341179697137, \"max\": 0.3160341179697137}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973401.8052056, \"EndTime\": 1619973401.8052325, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.3051895757574784, \"count\": 1, \"min\": 0.3051895757574784, \"max\": 0.3051895757574784}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973401.8052702, \"EndTime\": 1619973401.8052793, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.30306260086862663, \"count\": 1, \"min\": 0.30306260086862663, \"max\": 0.30306260086862663}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973401.8053396, \"EndTime\": 1619973401.805351, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 0.36318701348555715, \"count\": 1, \"min\": 0.36318701348555715, \"max\": 0.36318701348555715}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:41 INFO 140358224295744] #quality_metric: host=algo-1, epoch=4, train binary_classification_weighted_cross_entropy_objective <loss>=0.3065602360374049\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:41 INFO 140358224295744] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=binary_classification_weighted_cross_entropy_objective, value=0.30306260086862663\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:41 INFO 140358224295744] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:41 INFO 140358224295744] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:41 INFO 140358224295744] Saved checkpoint to \"/tmp/tmp_ivkhoa1/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:41 INFO 140358224295744] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973398.5061965, \"EndTime\": 1619973401.8123448, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 966100.0, \"count\": 1, \"min\": 966100, \"max\": 966100}, \"Total Batches Seen\": {\"sum\": 967.0, \"count\": 1, \"min\": 967, \"max\": 967}, \"Max Records Seen Between Resets\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Max Batches Seen Between Resets\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 190820.0, \"count\": 1, \"min\": 190820, \"max\": 190820}, \"Number of Batches Since Last Reset\": {\"sum\": 191.0, \"count\": 1, \"min\": 191, \"max\": 191}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:41 INFO 140358224295744] #throughput_metric: host=algo-1, train throughput=57713.71275908475 records/second\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:41 WARNING 140358224295744] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:41 WARNING 140358224295744] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] #train_score (algo-1) : ('binary_classification_weighted_cross_entropy_objective', 0.29129383753660704)\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] #train_score (algo-1) : ('binary_classification_accuracy', 0.998569332355099)\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] #train_score (algo-1) : ('binary_f_1.000', 0.3973509933774834)\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] #train_score (algo-1) : ('precision', 0.8181818181818182)\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] #train_score (algo-1) : ('recall', 0.26239067055393583)\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] #train_score (algo-1) : ('roc_auc_score', 0.9846922665884793)\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] #quality_metric: host=algo-1, train binary_classification_weighted_cross_entropy_objective <loss>=0.29129383753660704\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.998569332355099\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.3973509933774834\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] #quality_metric: host=algo-1, train precision <score>=0.8181818181818182\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] #quality_metric: host=algo-1, train recall <score>=0.26239067055393583\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] #quality_metric: host=algo-1, train roc_auc_score <score>=0.9846922665884793\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.005, \"wd\": 0.0001, \"l1\": 0.0, \"lr_scheduler_step\": 100, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 0.0001}\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] Saved checkpoint to \"/tmp/tmpp13djrul/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/02/2021 16:36:47 INFO 140358224295744] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619973384.205469, \"EndTime\": 1619973407.3493094, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 289.2889976501465, \"count\": 1, \"min\": 289.2889976501465, \"max\": 289.2889976501465}, \"epochs\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"check_early_stopping.time\": {\"sum\": 4.28462028503418, \"count\": 5, \"min\": 0.8246898651123047, \"max\": 0.8754730224609375}, \"update.time\": {\"sum\": 17280.46464920044, \"count\": 5, \"min\": 3224.1930961608887, \"max\": 4143.680810928345}, \"finalize.time\": {\"sum\": 5532.114028930664, \"count\": 1, \"min\": 5532.114028930664, \"max\": 5532.114028930664}, \"setuptime\": {\"sum\": 35.80975532531738, \"count\": 1, \"min\": 35.80975532531738, \"max\": 35.80975532531738}, \"totaltime\": {\"sum\": 23389.78409767151, \"count\": 1, \"min\": 23389.78409767151, \"max\": 23389.78409767151}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-05-02 16:37:04 Uploading - Uploading generated training model\n",
      "2021-05-02 16:37:04 Completed - Training job completed\n",
      "Training seconds: 95\n",
      "Billable seconds: 39\n",
      "Managed Spot Training savings: 58.9%\n"
     ]
    }
   ],
   "source": [
    "linear_learner.fit({'train':s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "059ffc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "# deploy and create a predictor\n",
    "linear_predictor = linear_learner.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a1aa477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictor.serializer = CSVSerializer()\n",
    "linear_predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b755eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for simple, LinearLearner.\n",
      "\n",
      "prediction (col)      0   1\n",
      "actual (row)               \n",
      "0                 93833   5\n",
      "1                   103  46\n",
      "\n",
      "Recall:     0.001\n",
      "Precision:  0.002\n",
      "Accuracy:   0.998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for simple, LinearLearner.\\n')\n",
    "\n",
    "# get metrics for linear predictor\n",
    "metrics = evaluate(linear_predictor, \n",
    "                   np.array(X_test).astype('float32'), \n",
    "                   np.array(y_test), \n",
    "                   verbose=True) # verbose means we'll print out the metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25c52e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'a67bcdf7-e1bb-4367-9571-99c21dd85874',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a67bcdf7-e1bb-4367-9571-99c21dd85874',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Sun, 02 May 2021 16:47:50 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.client('sagemaker').delete_endpoint(EndpointName=linear_predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
